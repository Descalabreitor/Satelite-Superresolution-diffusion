{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:11.569431Z",
     "start_time": "2024-04-15T08:21:09.560010Z"
    }
   },
   "source": [
    "import PIL\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Dataset.AerialDataset import AerialDataset\n",
    "from tasks.trainer import Trainer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Generar imagenes bicubicas\n",
    "- Construir Dataset\n",
    "- Construir Dataloader\n",
    "- SR3\n",
    "- SRdiff\n",
    "- SR3+"
   ],
   "id": "77744e547aa8b8f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 64 -> 256\n",
    "\n",
    "\n",
    "#### Generación de imagenes bicubicas"
   ],
   "id": "71bab7523f2c3892"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f8dda06f98beef4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.interpolate import interpn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "##TODO Mover esto a su propio modulo donde poder usarlo para preparar los datos a posteriori.\n",
    "## TODO cambiar metodo para q vaya más rapido.\n",
    "\n",
    "\n",
    "def bicubic_interpolation(image, objective_dim): # De momento lo implementare para 1 sola foto a la vez\n",
    "    #Calculo nuevas dimensiones\n",
    "    height, width = image.shape[0] , image.shape[1]\n",
    "    new_width, new_height = objective_dim[0], objective_dim[1]\n",
    "    new_image = np.zeros((new_height, new_width, image.shape[2]))\n",
    "    \n",
    "     # Generar cuadrículas para las coordenadas X e Y de la imagen original y la interpolada\n",
    "    x = np.linspace(0, width - 1, width)\n",
    "    y = np.linspace(0, height - 1, height)\n",
    "    new_x = np.linspace(0, width - 1, new_width)\n",
    "    new_y = np.linspace(0, height - 1, new_height)\n",
    "    new_image = interpn((y, x), image, (new_y[:,None], new_x), method='cubic', bounds_error=False, fill_value=0)\n",
    "    return new_image\n",
    "\n",
    "dataset_dir = 'E:\\\\TFG\\\\air_dataset\\\\64'\n",
    "for image_file in tqdm(os.listdir(dataset_dir)):\n",
    "    image = Image.open(os.path.join(dataset_dir, image_file))\n",
    "    image = np.array(image)\n",
    "    interpolated = bicubic_interpolation(image, (256, 256))\n",
    "    interpolated_image = Image.fromarray(interpolated.astype(np.uint8))\n",
    "    interpolated_image.save(f'E:\\\\TFG\\\\air_dataset\\\\sr\\\\64_256\\\\{image_file}')\n",
    "    "
   ],
   "id": "2c0f2381994a51d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento",
   "id": "830b031f8230ceb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:14.136790Z",
     "start_time": "2024-04-15T08:21:14.134547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "dataset_dir = 'E:\\\\TFG\\\\air_dataset'\n",
    "\n",
    "logs_dir = 'E:\\\\TFG\\\\logs'"
   ],
   "id": "4e91bfd9d2a1b993",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T08:21:36.495009Z",
     "start_time": "2024-04-15T08:21:30.580232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "trainer = Trainer(logs_dir=logs_dir)\n",
    "for epoch in range(epochs):\n",
    "    \n"
   ],
   "id": "dc17da4936ebfe5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m val_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m test_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(test_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_dataloader:\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhr\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     11\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\Dataset\\AerialDataset.py:27\u001B[0m, in \u001B[0;36mAerialDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     26\u001B[0m     lr_image \u001B[38;5;241m=\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_res_images[idx])\n\u001B[1;32m---> 27\u001B[0m     hr_image \u001B[38;5;241m=\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhigh_res_images[idx])\n\u001B[0;32m     28\u001B[0m     sr_image \u001B[38;5;241m=\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msr_res_images[idx])\n\u001B[0;32m     30\u001B[0m     lr_image \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mToTensor()(lr_image)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\PIL\\Image.py:3218\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3215\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[0;32m   3217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3218\u001B[0m     fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3219\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3221\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "73f8ada8e8ed58c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
