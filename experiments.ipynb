{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T17:18:51.196835Z",
     "start_time": "2024-05-26T17:18:48.472475Z"
    }
   },
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.v2 import Compose, GaussianBlur, RandomEqualize, RandomSolarize, RandomApply\n",
    "\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Dataset.AerialDataset import AerialDataset\n",
    "from tasks.SRDiffTrainer import SRDiffTrainer\n",
    "from tasks.SR3Trainer import SR3Trainer\n",
    "from utils.model_utils import load_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Generar imagenes bicubicas\n",
    "- Construir Dataset\n",
    "- Construir Dataloader\n",
    "- SR3\n",
    "- SRdiff\n",
    "- SR3+"
   ],
   "id": "77744e547aa8b8f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 64 -> 256",
   "id": "71bab7523f2c3892"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento",
   "id": "830b031f8230ceb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T17:18:51.200302Z",
     "start_time": "2024-05-26T17:18:51.197838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 16\n",
    "dataset_dir = 'E:\\\\TFG\\\\air_dataset'"
   ],
   "id": "4e91bfd9d2a1b993",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T17:18:51.277326Z",
     "start_time": "2024-05-26T17:18:51.200824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = transforms, aux_sat_prob= 0.5, sat_dataset_path= \"E:\\\\TFG\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "dc17da4936ebfe5e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SRDiff",
   "id": "ec73b68aba1d08bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.SRDiff.diffusion import GaussianDiffusion\n",
    "from models.SRDiff.diffsr_modules import Unet, RRDBNet\n",
    "losstype = \"l2\"\n",
    "model_name = f\"SRDiff{losstype}auxsatdata\"\n",
    "hidden_size = 64\n",
    "dim_mults = [1,2,2,4]\n",
    "rrdb_num_features = 32\n",
    "rrdb_num_blocks = 8\n",
    "timesteps = 100\n",
    "\n",
    "denoise_fn = Unet(\n",
    "    hidden_size, out_dim=3, cond_dim=rrdb_num_features, dim_mults=dim_mults, rrdb_num_block=rrdb_num_blocks, sr_scale=4)\n",
    "\n",
    "rrdb = RRDBNet(3, 3, rrdb_num_features, rrdb_num_blocks, rrdb_num_features// 2)\n",
    "\n",
    "model = GaussianDiffusion(\n",
    "    denoise_fn=denoise_fn,\n",
    "    rrdb_net=rrdb,\n",
    "    timesteps= timesteps,\n",
    "    loss_type=losstype,\n",
    "    aux_l1_loss=True,\n",
    "    aux_perceptual_loss=True\n",
    ")\n",
    "#model = load_model(model, f\"SRDiff{losstype}.pt\", \"models_state_dic\")\n",
    "model.to(device)  \n",
    "\n",
    "lr= 0.0002\n",
    "decay_steps= 100000\n",
    "gamma = 0.5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=gamma)\n",
    "max_steps = 5\n",
    "hyperparams = {\n",
    "    \"max_steps\": 100,\n",
    "    \"model\": \"SRDifftrainedRRDB\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"decay_steps\": decay_steps,\n",
    "    \"gamma\": gamma,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"dim_mults\": dim_mults,\n",
    "    \"rrdb_num_features\": rrdb_num_features,\n",
    "    \"rrdb_num_blocks\": rrdb_num_blocks,\n",
    "    \"loss_type\": losstype,\n",
    "    \"epochs\": max_steps,\n",
    "    \"use_rrdb\": True,\n",
    "    \"fix_rrdb\": False\n",
    "}\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=[\"ssim\", \"psnr\"], model_name=model_name)\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(max_steps):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    train_loss = trainer.train(train_dataloader, True, True)\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.save_model(\"models_state_dic\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()     "
   ],
   "id": "5c9bcb1d2dbd771e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "   ### SR3",
   "id": "56832a9822772ac4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T17:18:55.392661Z",
     "start_time": "2024-05-26T17:18:55.269856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.SR3.diffusion import GaussianDiffusion\n",
    "from models.SR3.model import UNet\n",
    "hyperparams = {\n",
    "    \"steps\" : 2000,\n",
    "    \"sample_steps\" : 100,\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":10,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\",\n",
    "    \"losstype\": \"l2\"\n",
    "}\n",
    "model = UNet(3, hyperparams[\"steps\"]) #Valores por defecto ya que la tarea base es la misma upsample por 4\n",
    "SR3_model = GaussianDiffusion(model, hyperparams[\"steps\"], hyperparams[\"sample_steps\"], losstype=\"l1\")\n",
    "SR3_model.to(device)"
   ],
   "id": "d9c705c5919a2ae7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion(\n",
       "  (model): UNet(\n",
       "    (emb): GammaEmbedding(\n",
       "      (linear1): Linear(\n",
       "        (linear): Linear(in_features=3, out_features=12, bias=True)\n",
       "      )\n",
       "      (silu): SiLU()\n",
       "      (linear2): Linear(\n",
       "        (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (down): ModuleList(\n",
       "      (0-2): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=3, out_features=9, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=3, out_features=3, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=3, out_features=6, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=18, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5-6): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=18, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9-10): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (12-14): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (16): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17-18): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20-22): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): ModuleList(\n",
       "      (0): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0-3): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5-7): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=12, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11-13): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15-17): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=6, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=18, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21-22): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=18, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=6, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=18, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=6, out_features=6, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (24): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (25): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=3, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=3, out_features=9, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=3, out_features=3, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (26-28): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=3, out_features=9, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=3, out_features=3, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gn): GroupNorm(\n",
       "      (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (conv2): Conv2d(\n",
       "      (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T17:18:58.642708Z",
     "start_time": "2024-05-26T17:18:58.637204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(SR3_model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "8de1ea6ba92768e5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T17:19:06.398869Z",
     "start_time": "2024-05-26T17:18:59.714541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 with aux satelite data\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=[\"ssim\", \"psnr\"], model_name=\"SR3\")\n",
    "trainer.set_model(SR3_model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.save_model(\"models_state_dic\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "50a99affdb90aa21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33madrianpereramoreno\u001B[0m (\u001B[33mladoscuro\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_181901-fc2ojl3e</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/fc2ojl3e' target=\"_blank\">SR3 with aux satelite data</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/fc2ojl3e' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/fc2ojl3e</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 11.99 GiB of which 10.60 GiB is free. Of the allocated memory 190.52 MiB is allocated by PyTorch, and 5.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(hyperparams[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 12\u001B[0m         val_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mvalidate(val_dataloader)\n\u001B[0;32m     14\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mtrain(train_dataloader)\n\u001B[0;32m     15\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\tasks\\SR3Trainer.py:55\u001B[0m, in \u001B[0;36mSR3Trainer.validate\u001B[1;34m(self, val_dataloader)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m val_pbar:\n\u001B[0;32m     54\u001B[0m     move_to_cuda(batch)\n\u001B[1;32m---> 55\u001B[0m     losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(batch)\n\u001B[0;32m     56\u001B[0m     final_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m losses\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m final_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(val_pbar)\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\tasks\\SR3Trainer.py:64\u001B[0m, in \u001B[0;36mSR3Trainer.training_step\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     62\u001B[0m img_lr \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     63\u001B[0m img_bicubic \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 64\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(img_hr, img_bicubic)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\diffusion.py:79\u001B[0m, in \u001B[0;36mGaussianDiffusion.forward\u001B[1;34m(self, x_0, x_c)\u001B[0m\n\u001B[0;32m     76\u001B[0m x_t \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msqrt(gamma) \u001B[38;5;241m*\u001B[39m x_0 \u001B[38;5;241m+\u001B[39m torch\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m gamma) \u001B[38;5;241m*\u001B[39m epsilon\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosstype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 79\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39ml1_loss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(torch\u001B[38;5;241m.\u001B[39mcat((x_t, x_c), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), torch\u001B[38;5;241m.\u001B[39msqrt(gamma)), epsilon, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosstype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     82\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(torch\u001B[38;5;241m.\u001B[39mcat((x_t, x_c), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), torch\u001B[38;5;241m.\u001B[39msqrt(gamma)), epsilon, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\model.py:71\u001B[0m, in \u001B[0;36mUNet.forward\u001B[1;34m(self, x, gamma)\u001B[0m\n\u001B[0;32m     68\u001B[0m connections\u001B[38;5;241m.\u001B[39mappend(z)\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown:\n\u001B[1;32m---> 71\u001B[0m     z \u001B[38;5;241m=\u001B[39m module(z, emb) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(module, WideResNetBlock) \u001B[38;5;28;01melse\u001B[39;00m module(z)\n\u001B[0;32m     72\u001B[0m     connections\u001B[38;5;241m.\u001B[39mappend(z)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmid:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\model.py:162\u001B[0m, in \u001B[0;36mWideResNetBlock.forward\u001B[1;34m(self, x, emb)\u001B[0m\n\u001B[0;32m    159\u001B[0m out \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m z\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_attention:\n\u001B[1;32m--> 162\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39matt(out)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\model.py:183\u001B[0m, in \u001B[0;36mSelfAttentionBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    180\u001B[0m qkv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mqkv(z)\u001B[38;5;241m.\u001B[39mview(B, H \u001B[38;5;241m*\u001B[39m W, \u001B[38;5;241m3\u001B[39m, C)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)  \u001B[38;5;66;03m# shape=(B,H,W,3*C) -> (3,B,H*W,C)\u001B[39;00m\n\u001B[0;32m    181\u001B[0m q, k, v \u001B[38;5;241m=\u001B[39m qkv[\u001B[38;5;241m0\u001B[39m], qkv[\u001B[38;5;241m1\u001B[39m], qkv[\u001B[38;5;241m2\u001B[39m]  \u001B[38;5;66;03m# (B,H*W,C)\u001B[39;00m\n\u001B[1;32m--> 183\u001B[0m w \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(q, k\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m/\u001B[39m (C \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m)  \u001B[38;5;66;03m# shape=(B,H*W,H*W)\u001B[39;00m\n\u001B[0;32m    184\u001B[0m attention \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(w)\n\u001B[0;32m    185\u001B[0m self_attention \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(attention, v)  \u001B[38;5;66;03m# shape=(B,H*W,C)\u001B[39;00m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 11.99 GiB of which 10.60 GiB is free. Of the allocated memory 190.52 MiB is allocated by PyTorch, and 5.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SR3+",
   "id": "169eea58514820d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:55:29.859459Z",
     "start_time": "2024-05-23T07:55:29.801446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.SR3plus.diffusion import GaussianDiffusion\n",
    "from models.SR3plus.model import UNet\n",
    "hyperparams = {\n",
    "    \"steps\" : 8000,\n",
    "    \"sample_steps\" : 100,\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":10,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,\n",
    "    \"model\" : \"SR3+\",\n",
    "    \"losstype\": \"l2\"\n",
    "}\n",
    "model = UNet(3, hyperparams[\"steps\"], channel_expansions= [1, 2, 4, 4, 4, 8, 8, 8])\n",
    "SR3plus_model = GaussianDiffusion(model, hyperparams[\"steps\"], hyperparams[\"sample_steps\"])\n",
    "SR3plus_model.to(device)"
   ],
   "id": "9f6bbb6f14180686",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion(\n",
       "  (model): UNet(\n",
       "    (emb): GammaEmbedding(\n",
       "      (linear1): Linear(\n",
       "        (linear): Linear(in_features=3, out_features=12, bias=True)\n",
       "      )\n",
       "      (silu): SiLU()\n",
       "      (linear2): Linear(\n",
       "        (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (down): ModuleList(\n",
       "      (0-2): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=3, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5-6): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9-10): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (12-14): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (16-18): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (19): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (21-22): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (23): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (24-26): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (27): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (28-30): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): ModuleList(\n",
       "      (0-1): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0-3): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5-8): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10-12): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (13): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (14): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (16-18): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (19): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20-23): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (24): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (25-27): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (28): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (29): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (30): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (31-32): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (33): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (34): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (35): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (36-38): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gn): GroupNorm(\n",
       "      (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (conv2): Conv2d(\n",
       "      (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T07:55:29.865453Z",
     "start_time": "2024-05-23T07:55:29.859459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(SR3plus_model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "2ec55b27c77c26fc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:05:25.404417Z",
     "start_time": "2024-05-23T07:55:29.866458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+  with aux satelite data\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=[\"ssim\", \"psnr\"], model_name=\"SR3+\")\n",
    "trainer.set_model(SR3plus_model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.save_model(\"models_state_dic\") \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "18c1250e157ff968",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0002ab615aa84c04b321fdbaef034a3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240523_085529-8wxycvun</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/8wxycvun' target=\"_blank\">SR3+  with aux satelite data</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/8wxycvun' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/8wxycvun</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:07<00:00,  6.35batch/s]\n",
      "100%|██████████| 148/148 [00:33<00:00,  4.47batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.82batch/s]\n",
      "100%|██████████| 148/148 [00:32<00:00,  4.50batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.70batch/s]\n",
      "100%|██████████| 148/148 [00:32<00:00,  4.62batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  7.09batch/s]\n",
      "100%|██████████| 148/148 [00:32<00:00,  4.60batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  7.13batch/s]\n",
      "100%|██████████| 148/148 [00:32<00:00,  4.61batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.45batch/s]\n",
      "100%|██████████| 148/148 [00:30<00:00,  4.86batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.62batch/s]\n",
      "100%|██████████| 148/148 [00:29<00:00,  4.99batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.96batch/s]\n",
      "100%|██████████| 148/148 [00:29<00:00,  5.02batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.96batch/s]\n",
      "100%|██████████| 148/148 [00:30<00:00,  4.79batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.63batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.11batch/s]\n",
      "100%|██████████| 50/50 [03:24<00:00,  4.08s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5d43c72b5754bb2ae616464544a5e7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▃▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▆▅▄▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.40912</td></tr><tr><td>ssim</td><td>0.00209</td></tr><tr><td>train_loss</td><td>0.34076</td></tr><tr><td>validation_loss</td><td>0.35272</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3+  with aux satelite data</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/8wxycvun' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/8wxycvun</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240523_085529-8wxycvun\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
