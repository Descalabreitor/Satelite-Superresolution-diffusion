{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T19:56:28.858083Z",
     "start_time": "2024-05-26T19:56:26.177199Z"
    }
   },
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.v2 import Compose, GaussianBlur, RandomEqualize, RandomSolarize, RandomApply\n",
    "\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Dataset.AerialDataset import AerialDataset\n",
    "from tasks.SR3Trainer import SR3Trainer\n",
    "from models.SR3Builder import SR3Builder\n",
    "from utils.model_utils import load_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T19:56:28.907132Z",
     "start_time": "2024-05-26T19:56:28.859088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Data\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 16\n",
    "dataset_dir = 'E:\\\\TFG\\\\air_dataset'\n",
    "\n",
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = None, aux_sat_prob= 0, sat_dataset_path= \"E:\\\\TFG\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "23cc5f6f2a487382",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T19:36:56.207935Z",
     "start_time": "2024-05-26T19:36:56.098859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "47acbdbe57f480a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion(\n",
       "  (model): UNet(\n",
       "    (emb): GammaEmbedding(\n",
       "      (linear1): Linear(\n",
       "        (linear): Linear(in_features=3, out_features=12, bias=True)\n",
       "      )\n",
       "      (silu): SiLU()\n",
       "      (linear2): Linear(\n",
       "        (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (down): ModuleList(\n",
       "      (0-2): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=3, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5-6): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9-10): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (12-14): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (16): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17-18): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20-22): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): ModuleList(\n",
       "      (0): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0-3): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5-7): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11-13): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (14): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15-17): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (18): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (19): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (21-22): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (23): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (24): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (25): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (26-28): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gn): GroupNorm(\n",
       "      (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (conv2): Conv2d(\n",
       "      (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T19:36:56.212810Z",
     "start_time": "2024-05-26T19:36:56.207935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "c720aad7cdead033",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T19:43:52.856560Z",
     "start_time": "2024-05-26T19:36:56.213816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "2ee13c55f04b587f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33madrianpereramoreno\u001B[0m (\u001B[33mladoscuro\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_203657-na2aduj7</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/na2aduj7' target=\"_blank\">SR3 standart</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/na2aduj7' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/na2aduj7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.60batch/s]\n",
      "100%|██████████| 148/148 [00:20<00:00,  7.36batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.43batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.51batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.42batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.55batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.39batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.48batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.41batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.47batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.34batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.49batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.41batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.48batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.37batch/s]\n",
      "100%|██████████| 148/148 [00:20<00:00,  7.36batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.26batch/s]\n",
      "100%|██████████| 148/148 [00:20<00:00,  7.14batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.91batch/s]\n",
      "100%|██████████| 148/148 [00:19<00:00,  7.56batch/s]\n",
      "100%|██████████| 50/50 [02:46<00:00,  3.33s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d206b11d06d14e0685140d2f8f84d2fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▅▄▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.46344</td></tr><tr><td>ssim</td><td>0.00253</td></tr><tr><td>train_loss</td><td>0.26535</td></tr><tr><td>validation_loss</td><td>0.28135</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3 standart</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/na2aduj7' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/na2aduj7</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_203657-na2aduj7\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T19:43:53.050623Z",
     "start_time": "2024-05-26T19:43:52.857564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "4f6099cdb79119d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion(\n",
       "  (model): UNet(\n",
       "    (emb): GammaEmbedding(\n",
       "      (linear1): Linear(\n",
       "        (linear): Linear(in_features=3, out_features=12, bias=True)\n",
       "      )\n",
       "      (silu): SiLU()\n",
       "      (linear2): Linear(\n",
       "        (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (down): ModuleList(\n",
       "      (0-2): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=3, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5-6): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9-10): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (12-14): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (16): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17-18): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20-22): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): ModuleList(\n",
       "      (0): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0-3): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5-7): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (10): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11-13): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (14): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (15-17): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (18): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (19): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (20): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (21-22): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (23): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (24): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (25): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (26-28): 3 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gn): GroupNorm(\n",
       "      (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (conv2): Conv2d(\n",
       "      (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:22:59.561875Z",
     "start_time": "2024-05-26T21:22:59.556088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "76ca52491d820553",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:23:11.092098Z",
     "start_time": "2024-05-26T21:23:00.997182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart with l1 loss\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart l2 loss\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "16727466aaddecb9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_222301-utx3ur90</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/utx3ur90' target=\"_blank\">SR3 standart with l1 loss</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/utx3ur90' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/utx3ur90</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.61batch/s]\n",
      " 11%|█▏        | 17/148 [00:02<00:22,  5.73batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     12\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mvalidate(val_dataloader)\n\u001B[1;32m---> 14\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mtrain(train_dataloader)\n\u001B[0;32m     15\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\tasks\\SR3Trainer.py:36\u001B[0m, in \u001B[0;36mSR3Trainer.train\u001B[1;34m(self, train_dataloader)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     35\u001B[0m move_to_cuda(batch)\n\u001B[1;32m---> 36\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(batch)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     39\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\tasks\\SR3Trainer.py:64\u001B[0m, in \u001B[0;36mSR3Trainer.training_step\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     62\u001B[0m img_lr \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     63\u001B[0m img_bicubic \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 64\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(img_hr, img_bicubic)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\diffusion.py:79\u001B[0m, in \u001B[0;36mGaussianDiffusion.forward\u001B[1;34m(self, x_0, x_c)\u001B[0m\n\u001B[0;32m     76\u001B[0m x_t \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msqrt(gamma) \u001B[38;5;241m*\u001B[39m x_0 \u001B[38;5;241m+\u001B[39m torch\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m gamma) \u001B[38;5;241m*\u001B[39m epsilon\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosstype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 79\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39ml1_loss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(torch\u001B[38;5;241m.\u001B[39mcat((x_t, x_c), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), torch\u001B[38;5;241m.\u001B[39msqrt(gamma)), epsilon, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosstype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     82\u001B[0m     loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(torch\u001B[38;5;241m.\u001B[39mcat((x_t, x_c), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), torch\u001B[38;5;241m.\u001B[39msqrt(gamma)), epsilon, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\model.py:87\u001B[0m, in \u001B[0;36mUNet.forward\u001B[1;34m(self, x, gamma)\u001B[0m\n\u001B[0;32m     84\u001B[0m     z \u001B[38;5;241m=\u001B[39m module(z, emb)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup:\n\u001B[1;32m---> 87\u001B[0m     z \u001B[38;5;241m=\u001B[39m module(torch\u001B[38;5;241m.\u001B[39mcat((z, connections\u001B[38;5;241m.\u001B[39mpop()), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), emb) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(module,\n\u001B[0;32m     88\u001B[0m                                                                             WideResNetBlock) \u001B[38;5;28;01melse\u001B[39;00m module(z)\n\u001B[0;32m     90\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgn(z)\n\u001B[0;32m     91\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msilu(z)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\model.py:149\u001B[0m, in \u001B[0;36mWideResNetBlock.forward\u001B[1;34m(self, x, emb)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, emb):\n\u001B[1;32m--> 149\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgn1(x)\n\u001B[0;32m    150\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msilu1(z)\n\u001B[0;32m    151\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(z)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\TFG-code\\SR-model-benchmarking\\models\\SR3\\model.py:227\u001B[0m, in \u001B[0;36mGroupNorm.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m--> 227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup_norm(x)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:287\u001B[0m, in \u001B[0;36mGroupNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mgroup_norm(\n\u001B[0;32m    288\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_groups, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meps)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\functional.py:2561\u001B[0m, in \u001B[0;36mgroup_norm\u001B[1;34m(input, num_groups, weight, bias, eps)\u001B[0m\n\u001B[0;32m   2559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected at least 2 dimensions for input tensor but received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2560\u001B[0m _verify_batch_size([\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_groups, num_groups] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m2\u001B[39m:]))\n\u001B[1;32m-> 2561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mgroup_norm(\u001B[38;5;28minput\u001B[39m, num_groups, weight, bias, eps, torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcudnn\u001B[38;5;241m.\u001B[39menabled)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:23:14.730489Z",
     "start_time": "2024-05-26T21:23:14.667128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "aaee9864f204abca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion(\n",
       "  (model): UNet(\n",
       "    (emb): GammaEmbedding(\n",
       "      (linear1): Linear(\n",
       "        (linear): Linear(in_features=3, out_features=12, bias=True)\n",
       "      )\n",
       "      (silu): SiLU()\n",
       "      (linear2): Linear(\n",
       "        (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (down): ModuleList(\n",
       "      (0-4): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=3, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7-10): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (12): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (13-16): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (17): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (18-22): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (23): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (24): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (25-28): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (29): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (30-34): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): ModuleList(\n",
       "      (0-1): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0-5): 6 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7-11): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (14): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (15-19): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (20): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (21-25): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (26): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (27): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (28): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (29-32): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (33): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (34): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (35): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (36-40): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gn): GroupNorm(\n",
       "      (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (conv2): Conv2d(\n",
       "      (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:23:15.660359Z",
     "start_time": "2024-05-26T21:23:15.652939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "251bcb3352d85919",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:54:29.596072Z",
     "start_time": "2024-05-26T21:23:18.827384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ standart\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3+\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "c0e5e79867cbfb2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:utx3ur90) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b547453034f4b159c07b0238753e9f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "W&B sync reduced upload amount by 11.8%             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3 standart with l1 loss</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/utx3ur90' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/utx3ur90</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_222301-utx3ur90\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:utx3ur90). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01128888888876342, max=1.0)…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c679fee297624dbdac044ce341adcf76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_222318-hdocqxa1</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/hdocqxa1' target=\"_blank\">SR3+ standart</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/hdocqxa1' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/hdocqxa1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.75batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.98batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.14batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.02batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.29batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.02batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.12batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.04batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.09batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.97batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.25batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.02batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.04batch/s]\n",
      "100%|██████████| 148/148 [00:25<00:00,  5.75batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.02batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.04batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.10batch/s]\n",
      "100%|██████████| 148/148 [00:25<00:00,  5.91batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.01batch/s]\n",
      "100%|██████████| 148/148 [00:25<00:00,  5.86batch/s]\n",
      "100%|██████████| 50/50 [25:58<00:00, 31.18s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.007 MB uploaded\\r'), FloatProgress(value=0.18531275833562966, max=1.…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f9f75b0fd404c6fbd956fc1b147ee6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.29622</td></tr><tr><td>ssim</td><td>0.0021</td></tr><tr><td>train_loss</td><td>0.22239</td></tr><tr><td>validation_loss</td><td>0.23629</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3+ standart</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/hdocqxa1' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/hdocqxa1</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_222318-hdocqxa1\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:54:29.663359Z",
     "start_time": "2024-05-26T21:54:29.597077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "361796a504f0a35d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion(\n",
       "  (model): UNet(\n",
       "    (emb): GammaEmbedding(\n",
       "      (linear1): Linear(\n",
       "        (linear): Linear(in_features=3, out_features=12, bias=True)\n",
       "      )\n",
       "      (silu): SiLU()\n",
       "      (linear2): Linear(\n",
       "        (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (down): ModuleList(\n",
       "      (0-4): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (6): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=3, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7-10): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (11): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (12): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (13-16): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (17): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (18-22): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (23): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (24): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (25-28): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (29): DownBlock(\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (30-34): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid): ModuleList(\n",
       "      (0-1): 2 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0-5): 6 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (7-11): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 48, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=48, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=24, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=24, bias=True)\n",
       "        )\n",
       "        (att): SelfAttentionBlock(\n",
       "          (gn): GroupNorm(\n",
       "            (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (qkv): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=72, bias=True)\n",
       "          )\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (proj): Linear(\n",
       "            (linear): Linear(in_features=24, out_features=24, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (14): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 36, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=36, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (15-19): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (20): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (21-25): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 24, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=24, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (26): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=12, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (27): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (28): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 18, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(18, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=18, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (29-32): 4 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 12, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (33): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=6, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (34): UpBlock(\n",
       "        (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (conv): Conv2d(\n",
       "          (conv): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (35): WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 9, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=9, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (36-40): 5 x WideResNetBlock(\n",
       "        (gn1): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 6, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu1): SiLU()\n",
       "        (conv1): Conv2d(\n",
       "          (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (silu2): SiLU()\n",
       "        (linear1): Linear(\n",
       "          (linear): Linear(in_features=12, out_features=3, bias=True)\n",
       "        )\n",
       "        (gn2): GroupNorm(\n",
       "          (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (silu3): SiLU()\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (conv2): Conv2d(\n",
       "          (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (linear2): Linear(\n",
       "          (linear): Linear(in_features=6, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gn): GroupNorm(\n",
       "      (group_norm): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (conv2): Conv2d(\n",
       "      (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:54:29.670720Z",
     "start_time": "2024-05-26T21:54:29.664365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "8eae72e4d3871d2a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:24:36.746148Z",
     "start_time": "2024-05-26T21:54:29.671724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart with l1 loss\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ standart l1 loss\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3+\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "5e18ad7a112fecf4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfd102d753944dd5bdb11eac5ecf88c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_225429-3kjy8jxh</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/3kjy8jxh' target=\"_blank\">SR3+ standart with l1 loss</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/3kjy8jxh' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/3kjy8jxh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.58batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.96batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.07batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.96batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.13batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.00batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.16batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.93batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.08batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.01batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.13batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.98batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.10batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.95batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.05batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.97batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.90batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.94batch/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.07batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.00batch/s]\n",
      "100%|██████████| 50/50 [25:04<00:00, 30.09s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3025a566400c4d0eb09905e3b394a6fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▃▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▆▅▄▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.1553</td></tr><tr><td>ssim</td><td>0.00193</td></tr><tr><td>train_loss</td><td>0.34665</td></tr><tr><td>validation_loss</td><td>0.36108</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3+ standart with l1 loss</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/3kjy8jxh' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/3kjy8jxh</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_225429-3kjy8jxh\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:24:36.848019Z",
     "start_time": "2024-05-26T22:24:36.747153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Data\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 16\n",
    "dataset_dir = 'E:\\\\TFG\\\\air_dataset'\n",
    "\n",
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = transforms, aux_sat_prob= 0.6, sat_dataset_path= \"E:\\\\TFG\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "d34b93b2835c22bd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:35:14.916973Z",
     "start_time": "2024-05-26T22:24:36.848788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart with data augmentation\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart DA\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "2a90a0a9f034f694",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5361f5c534a14bf2bd2a435bb39c1efc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_232436-zbj1v28j</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/zbj1v28j' target=\"_blank\">SR3 standart with data augmentation</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/zbj1v28j' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/zbj1v28j</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.92batch/s]\n",
      "100%|██████████| 148/148 [00:41<00:00,  3.57batch/s]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.01batch/s]\n",
      "100%|██████████| 148/148 [00:39<00:00,  3.75batch/s]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.39batch/s]\n",
      "100%|██████████| 148/148 [00:38<00:00,  3.85batch/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.22batch/s]\n",
      "100%|██████████| 148/148 [00:41<00:00,  3.54batch/s]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.41batch/s]\n",
      "100%|██████████| 148/148 [00:36<00:00,  4.07batch/s]\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.96batch/s]\n",
      "100%|██████████| 148/148 [00:34<00:00,  4.29batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34batch/s]\n",
      "100%|██████████| 148/148 [00:33<00:00,  4.37batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.66batch/s]\n",
      "100%|██████████| 148/148 [00:33<00:00,  4.44batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.98batch/s]\n",
      "100%|██████████| 148/148 [00:31<00:00,  4.64batch/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.94batch/s]\n",
      "100%|██████████| 148/148 [00:30<00:00,  4.83batch/s]\n",
      "100%|██████████| 50/50 [02:56<00:00,  3.54s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f7c098878c1426e906c60d025a86497"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▄▄▃▂▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▅▄▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.47533</td></tr><tr><td>ssim</td><td>0.00206</td></tr><tr><td>train_loss</td><td>0.25841</td></tr><tr><td>validation_loss</td><td>0.27198</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3 standart with data augmentation</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/zbj1v28j' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/zbj1v28j</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_232436-zbj1v28j\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T22:43:41.925786Z",
     "start_time": "2024-05-26T22:35:14.917988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart l1 with data augmentation\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart l1 DA\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "25d0c3c49ec321d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdf225e8ad0443db852edb20afcdb42d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_233514-n063ob2o</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/n063ob2o' target=\"_blank\">SR3 standart l1 with data augmentation</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/n063ob2o' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/n063ob2o</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.38batch/s]\n",
      "100%|██████████| 148/148 [00:29<00:00,  5.05batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.33batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.14batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  8.06batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.20batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.96batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.28batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  8.12batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.61batch/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  8.18batch/s]\n",
      "100%|██████████| 148/148 [00:25<00:00,  5.71batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.54batch/s]\n",
      "100%|██████████| 148/148 [00:25<00:00,  5.78batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.59batch/s]\n",
      "100%|██████████| 148/148 [00:25<00:00,  5.86batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.82batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  5.98batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.84batch/s]\n",
      "100%|██████████| 148/148 [00:24<00:00,  6.12batch/s]\n",
      "100%|██████████| 50/50 [02:50<00:00,  3.42s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.007 MB uploaded\\r'), FloatProgress(value=0.17918998134825473, max=1.…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e7ddfea097547a883e21c533a8366c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▂▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.4504</td></tr><tr><td>ssim</td><td>0.00207</td></tr><tr><td>train_loss</td><td>0.45376</td></tr><tr><td>validation_loss</td><td>0.46191</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3 standart l1 with data augmentation</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/n063ob2o' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/n063ob2o</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_233514-n063ob2o\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:14:38.260327Z",
     "start_time": "2024-05-26T22:43:41.926791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart with data augmentation\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ Standart DA\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "d4cfe81f2032769c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26272fdc8f714f10809482729ba3b0ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240526_234341-i5qlt0o9</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/i5qlt0o9' target=\"_blank\">SR3 standart with data augmentation</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/i5qlt0o9' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/i5qlt0o9</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  8.16batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.13batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.70batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.11batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.66batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.21batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.93batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.32batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.98batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.34batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  8.93batch/s]\n",
      "100%|██████████| 148/148 [00:28<00:00,  5.27batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.30batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.37batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.19batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.37batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.24batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.40batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.05batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.42batch/s]\n",
      "100%|██████████| 50/50 [25:10<00:00, 30.20s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20f8e3b9b3324f26b8171a616e2cba07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.20645</td></tr><tr><td>ssim</td><td>0.00196</td></tr><tr><td>train_loss</td><td>0.22661</td></tr><tr><td>validation_loss</td><td>0.24179</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3 standart with data augmentation</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/i5qlt0o9' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/i5qlt0o9</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240526_234341-i5qlt0o9\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:45:14.409606Z",
     "start_time": "2024-05-26T23:14:38.261331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart l1 with data augmentation\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ Standart l1 DA\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "c916f18d72185b7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc0e75493ba849fca4667b826f17ec71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adria\\Desktop\\TFG-code\\SR-model-benchmarking\\wandb\\run-20240527_001438-mwldwa2d</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/mwldwa2d' target=\"_blank\">SR3+ standart l1 with data augmentation</a></strong> to <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/mwldwa2d' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/mwldwa2d</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  8.77batch/s]\n",
      "100%|██████████| 148/148 [00:27<00:00,  5.43batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.27batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.49batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.52batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.52batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.25batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.55batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.57batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.57batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.65batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.53batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.72batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.54batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.75batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.53batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.50batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.61batch/s]\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.89batch/s]\n",
      "100%|██████████| 148/148 [00:26<00:00,  5.56batch/s]\n",
      "100%|██████████| 50/50 [25:05<00:00, 30.11s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddb1f6fe2aa7492f94c25e31d5a859de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▃▂▁▁</td></tr><tr><td>validation_loss</td><td>█▇▆▅▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>4.04618</td></tr><tr><td>ssim</td><td>0.00188</td></tr><tr><td>train_loss</td><td>0.3336</td></tr><tr><td>validation_loss</td><td>0.34675</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SR3+ standart l1 with data augmentation</strong> at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/mwldwa2d' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking/runs/mwldwa2d</a><br/> View project at: <a href='https://wandb.ai/ladoscuro/SR%20model%20benchmarking' target=\"_blank\">https://wandb.ai/ladoscuro/SR%20model%20benchmarking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240527_001438-mwldwa2d\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
