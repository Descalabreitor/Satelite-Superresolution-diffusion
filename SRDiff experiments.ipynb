{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T08:45:35.063547Z",
     "start_time": "2024-06-11T08:45:30.264526Z"
    }
   },
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.v2 import Compose, GaussianBlur, RandomEqualize, RandomSolarize, RandomApply\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Dataset.AerialDataset import AerialDataset\n",
    "from tasks.SRDiffTrainer import SRDiffTrainer\n",
    "from models.SRDIFFBuilder import SRDiffBuilder\n",
    "from utils.model_utils import load_model\n",
    "\n",
    "#Data\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 20\n",
    "dataset_dir = 'C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg'\n",
    "\n",
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = None, aux_sat_prob= 0.4, sat_dataset_path= \"C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device(0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T09:48:12.718650Z",
     "start_time": "2024-06-11T09:39:43.161995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "hyperparams = {\n",
    "    \"lr\": 0.00002,\n",
    "    \"model_name\": f\"SRDiff Percp loss\",\n",
    "    \"epochs\": 200,\n",
    "    \"eta_min\": 1e-7,\n",
    "    \"num_workers\":torch.cuda.device_count(),\n",
    "    \"mode\": \"min\",\n",
    "    \"patience\": 5,\n",
    "    \"factor\": 0.1,\n",
    "    \"model\": \"SRDiff\",\n",
    "    \"batch_size\": 20,\n",
    "    \"ddp\": True,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\": True,\n",
    "    \"fix_rrdb\": False,\n",
    "    \"aux_l1_loss\": False,\n",
    "    \"aux_perceptual_loss\": True,\n",
    "    \"aux_ssim_loss\": False,\n",
    "    \"losstype\": \"l1\"\n",
    "}\n",
    "\n",
    "model_builder = SRDiffBuilder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_losstype(hyperparams[\"losstype\"], hyperparams[\"aux_l1_loss\"], hyperparams[\"aux_perceptual_loss\"])\n",
    "model = model_builder.build()\n",
    "model_data = model_builder.get_hyperparameters()\n",
    "model.to(device)\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=hyperparams[\"model_name\"],\n",
    "                            device=device, use_rrdb=hyperparams[\"use_rrdb\"],\n",
    "                            fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                            aux_l1_loss=hyperparams[\"aux_l1_loss\"],\n",
    "                            aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"])\n",
    "\n",
    "model = load_model(model, \"SRDiff Percp loss199.pt\", \"saved models\\\\SRDiff\\\\Distributed\\\\Version 2\")\n",
    "\n",
    "trainer.set_model(model)\n",
    "\n",
    "wandb.login()\n",
    "wandb.init(project=\"SRDiff experiments\", config=hyperparams.update(model_data), name=f\"{hyperparams[\"model_name\"]} version 2 testing\",\n",
    "               group=f\"{hyperparams[\"model_name\"]} version 2 ddp group\")\n",
    "\n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)"
   ],
   "id": "4ca6310a039b13e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrianperera\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adrianperera\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model weights have been loaded from 'saved models\\SRDiff\\Distributed\\Version 2\\SRDiff Percp loss199.pt'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:z60ladoq) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e55d890582e453db752a5c57c7f1824"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "W&B sync reduced upload amount by 20.2%             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>▁</td></tr><tr><td>ssim</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>psnr</td><td>17.86586</td></tr><tr><td>ssim</td><td>0.55544</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SRDiff Percp loss version 3 testing</strong> at: <a href='https://wandb.ai/ladoscuro/SRDiff%20experiments/runs/z60ladoq/workspace' target=\"_blank\">https://wandb.ai/ladoscuro/SRDiff%20experiments/runs/z60ladoq/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240611_094538-z60ladoq\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:z60ladoq). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888886984852, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd17355047cc4697a6e97d2094c496a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adrianperera\\Desktop\\SR-model-benchmarking\\wandb\\run-20240611_103944-w61fwhbb</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ladoscuro/SRDiff%20experiments/runs/w61fwhbb/workspace' target=\"_blank\">SRDiff Percp loss version 2 testing</a></strong> to <a href='https://wandb.ai/ladoscuro/SRDiff%20experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ladoscuro/SRDiff%20experiments' target=\"_blank\">https://wandb.ai/ladoscuro/SRDiff%20experiments</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ladoscuro/SRDiff%20experiments/runs/w61fwhbb/workspace' target=\"_blank\">https://wandb.ai/ladoscuro/SRDiff%20experiments/runs/w61fwhbb/workspace</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [08:18<00:00, 12.45s/batch, psnr=6.39, ssim=-0.307]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T21:29:44.141455Z",
     "start_time": "2024-06-03T19:25:07.748460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"SRDIFF standart version 1.5\"\n",
    "hyperparams = {\n",
    "    \"lr\":0.00002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 1000000,\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\":0.5,\n",
    "    \"model\" : \"SRDiff\",\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"ddp\": False,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\":True,\n",
    "    \"fix_rrdb\":True,\n",
    "    \"aux_l1_loss\":False,\n",
    "    \"aux_perceptual_loss\":False,\n",
    "    \"aux_ssim_loss\":False\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "params = list(model.named_parameters())\n",
    "if not hyperparams['fix_rrdb']:\n",
    "    params = [p for p in params if 'rrdb' not in p[0]]\n",
    "params = [p[1] for p in params]\n",
    "optimizer =  torch.optim.Adam(params, lr=hyperparams['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"factor\"])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "project_name = \"SRDiff experiments\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=model_name, device=device, \n",
    "                        use_rrdb=hyperparams[\"use_rrdb\"], fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                        aux_l1_loss=hyperparams[\"aux_l1_loss\"], aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"],\n",
    "                        grad_acum=hyperparams[\"grad_acum\"])\n",
    "\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = trainer.train(train_dataloader, step)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SRDiff\\\\depured tests\\\\\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()"
   ],
   "id": "33b77f63a2a76c33",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T23:34:11.170330Z",
     "start_time": "2024-06-03T21:29:44.142455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SRDiffBuilder()\n",
    "model = model_builder.set_standart().build()\n",
    "model.to(device)\n",
    "\n",
    "model_name = \"SRDIFF standart version 2.5\"\n",
    "hyperparams = {\n",
    "    \"lr\":0.00002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 1000000,\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\":0.5,\n",
    "    \"model\" : \"SRDiff\",\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"ddp\": False,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\":True,\n",
    "    \"fix_rrdb\":True,\n",
    "    \"aux_l1_loss\":True,\n",
    "    \"aux_perceptual_loss\":False,\n",
    "    \"aux_ssim_loss\":False\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "params = list(model.named_parameters())\n",
    "if not hyperparams['fix_rrdb']:\n",
    "    params = [p for p in params if 'rrdb' not in p[0]]\n",
    "params = [p[1] for p in params]\n",
    "optimizer =  torch.optim.Adam(params, lr=hyperparams['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"factor\"])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "project_name = \"SRDiff experiments\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=model_name, device=device, \n",
    "                        use_rrdb=hyperparams[\"use_rrdb\"], fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                        aux_l1_loss=hyperparams[\"aux_l1_loss\"], aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"],\n",
    "                        grad_acum=hyperparams[\"grad_acum\"])\n",
    "\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = trainer.train(train_dataloader, step)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SRDiff\\\\depured tests\\\\\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()"
   ],
   "id": "72b56d51a72ae4e8",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T01:38:20.240502Z",
     "start_time": "2024-06-03T23:34:11.171831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SRDiffBuilder()\n",
    "model = model_builder.set_standart().build()\n",
    "model.to(device)\n",
    "\n",
    "model_name = \"SRDIFF standart version 3.5\"\n",
    "hyperparams = {\n",
    "    \"lr\":0.00002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 1000000,\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\":0.5,\n",
    "    \"model\" : \"SRDiff\",\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"ddp\": False,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\":True,\n",
    "    \"fix_rrdb\":True,\n",
    "    \"aux_l1_loss\":True,\n",
    "    \"aux_perceptual_loss\":False,\n",
    "    \"aux_ssim_loss\":True\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "params = list(model.named_parameters())\n",
    "if not hyperparams['fix_rrdb']:\n",
    "    params = [p for p in params if 'rrdb' not in p[0]]\n",
    "params = [p[1] for p in params]\n",
    "optimizer =  torch.optim.Adam(params, lr=hyperparams['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"factor\"])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "project_name = \"SRDiff experiments\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=model_name, device=device, \n",
    "                        use_rrdb=hyperparams[\"use_rrdb\"], fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                        aux_l1_loss=hyperparams[\"aux_l1_loss\"], aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"],\n",
    "                        grad_acum=hyperparams[\"grad_acum\"])\n",
    "\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = trainer.train(train_dataloader, step)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SRDiff\\\\depured tests\\\\\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()"
   ],
   "id": "f61cb9b0305456fd",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T02:18:03.149605Z",
     "start_time": "2024-06-04T01:38:20.242340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.SR3Builder import SR3Builder\n",
    "from tasks.SR3Trainer import SR3Trainer\n",
    "\n",
    "\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 128\n",
    "dataset_dir = 'C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg'\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = None, aux_sat_prob= 0.5, sat_dataset_path= \"C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device(0)\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_sample_steps(1000)\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\",\n",
    "    \"grad_acum\": 0,\n",
    "    \"ddp\": False,\n",
    "    \"batch_size\":batch_size\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart l1, 128Batch, 100k sampling\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart l1 DA 128b 100k sampling\", grad_acum=hyperparams[\"grad_acum\"])\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for epoch in range(hyperparams[\"epochs\"]):  \n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader, epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    if epoch % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "4c12c3b65605707c",
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
