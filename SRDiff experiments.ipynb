{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T19:25:07.501006Z",
     "start_time": "2024-06-03T19:25:03.947286Z"
    }
   },
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.v2 import Compose, GaussianBlur, RandomEqualize, RandomSolarize, RandomApply\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Dataset.AerialDataset import AerialDataset\n",
    "from tasks.SRDiffTrainer import SRDiffTrainer\n",
    "from models.SRDIFFBuilder import SRDiffBuilder\n",
    "from utils.model_utils import load_model\n",
    "\n",
    "#Data\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 20\n",
    "dataset_dir = 'C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg'\n",
    "\n",
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = None, aux_sat_prob= 0.4, sat_dataset_path= \"C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device(0)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:25:07.747460Z",
     "start_time": "2024-06-03T19:25:07.502460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SRDiffBuilder()\n",
    "model = model_builder.set_standart().build()\n",
    "model.to(device)"
   ],
   "id": "7f21f8354f327860",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T21:29:44.141455Z",
     "start_time": "2024-06-03T19:25:07.748460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"SRDIFF standart version 1.5\"\n",
    "hyperparams = {\n",
    "    \"lr\":0.00002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 1000000,\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\":0.5,\n",
    "    \"model\" : \"SRDiff\",\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"ddp\": False,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\":True,\n",
    "    \"fix_rrdb\":True,\n",
    "    \"aux_l1_loss\":False,\n",
    "    \"aux_perceptual_loss\":False,\n",
    "    \"aux_ssim_loss\":False\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "params = list(model.named_parameters())\n",
    "if not hyperparams['fix_rrdb']:\n",
    "    params = [p for p in params if 'rrdb' not in p[0]]\n",
    "params = [p[1] for p in params]\n",
    "optimizer =  torch.optim.Adam(params, lr=hyperparams['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"factor\"])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "project_name = \"SRDiff experiments\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=model_name, device=device, \n",
    "                        use_rrdb=hyperparams[\"use_rrdb\"], fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                        aux_l1_loss=hyperparams[\"aux_l1_loss\"], aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"],\n",
    "                        grad_acum=hyperparams[\"grad_acum\"])\n",
    "\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = trainer.train(train_dataloader, step)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SRDiff\\\\depured tests\\\\\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()"
   ],
   "id": "33b77f63a2a76c33",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T23:34:11.170330Z",
     "start_time": "2024-06-03T21:29:44.142455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SRDiffBuilder()\n",
    "model = model_builder.set_standart().build()\n",
    "model.to(device)\n",
    "\n",
    "model_name = \"SRDIFF standart version 2.5\"\n",
    "hyperparams = {\n",
    "    \"lr\":0.00002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 1000000,\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\":0.5,\n",
    "    \"model\" : \"SRDiff\",\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"ddp\": False,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\":True,\n",
    "    \"fix_rrdb\":True,\n",
    "    \"aux_l1_loss\":True,\n",
    "    \"aux_perceptual_loss\":False,\n",
    "    \"aux_ssim_loss\":False\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "params = list(model.named_parameters())\n",
    "if not hyperparams['fix_rrdb']:\n",
    "    params = [p for p in params if 'rrdb' not in p[0]]\n",
    "params = [p[1] for p in params]\n",
    "optimizer =  torch.optim.Adam(params, lr=hyperparams['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"factor\"])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "project_name = \"SRDiff experiments\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=model_name, device=device, \n",
    "                        use_rrdb=hyperparams[\"use_rrdb\"], fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                        aux_l1_loss=hyperparams[\"aux_l1_loss\"], aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"],\n",
    "                        grad_acum=hyperparams[\"grad_acum\"])\n",
    "\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = trainer.train(train_dataloader, step)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SRDiff\\\\depured tests\\\\\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()"
   ],
   "id": "72b56d51a72ae4e8",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T01:38:20.240502Z",
     "start_time": "2024-06-03T23:34:11.171831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SRDiffBuilder()\n",
    "model = model_builder.set_standart().build()\n",
    "model.to(device)\n",
    "\n",
    "model_name = \"SRDIFF standart version 3.5\"\n",
    "hyperparams = {\n",
    "    \"lr\":0.00002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 1000000,\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\":0.5,\n",
    "    \"model\" : \"SRDiff\",\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"ddp\": False,\n",
    "    \"grad_acum\": 1,\n",
    "    \"use_rrdb\":True,\n",
    "    \"fix_rrdb\":True,\n",
    "    \"aux_l1_loss\":True,\n",
    "    \"aux_perceptual_loss\":False,\n",
    "    \"aux_ssim_loss\":True\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "params = list(model.named_parameters())\n",
    "if not hyperparams['fix_rrdb']:\n",
    "    params = [p for p in params if 'rrdb' not in p[0]]\n",
    "params = [p[1] for p in params]\n",
    "optimizer =  torch.optim.Adam(params, lr=hyperparams['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"factor\"])\n",
    "torch.backends.cudnn.benchmark = True\n",
    "project_name = \"SRDiff experiments\"\n",
    "run_name = model_name\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SRDiffTrainer(metrics_used=(\"ssim\", \"psnr\"), model_name=model_name, device=device, \n",
    "                        use_rrdb=hyperparams[\"use_rrdb\"], fix_rrdb=hyperparams[\"fix_rrdb\"], aux_ssim_loss=hyperparams[\"aux_ssim_loss\"],\n",
    "                        aux_l1_loss=hyperparams[\"aux_l1_loss\"], aux_perceptual_loss=hyperparams[\"aux_perceptual_loss\"],\n",
    "                        grad_acum=hyperparams[\"grad_acum\"])\n",
    "\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = trainer.train(train_dataloader, step)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SRDiff\\\\depured tests\\\\\")\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()"
   ],
   "id": "f61cb9b0305456fd",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T02:18:03.149605Z",
     "start_time": "2024-06-04T01:38:20.242340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.SR3Builder import SR3Builder\n",
    "from tasks.SR3Trainer import SR3Trainer\n",
    "\n",
    "\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 128\n",
    "dataset_dir = 'C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg'\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = None, aux_sat_prob= 0.5, sat_dataset_path= \"C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device(0)\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_sample_steps(1000)\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\",\n",
    "    \"grad_acum\": 0,\n",
    "    \"ddp\": False,\n",
    "    \"batch_size\":batch_size\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart l1, 128Batch, 100k sampling\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart l1 DA 128b 100k sampling\", grad_acum=hyperparams[\"grad_acum\"])\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for epoch in range(hyperparams[\"epochs\"]):  \n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader, epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    if epoch % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "4c12c3b65605707c",
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
