{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:55:01.502372Z",
     "start_time": "2024-05-28T15:55:01.206373Z"
    }
   },
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.v2 import Compose, GaussianBlur, RandomEqualize, RandomSolarize, RandomApply\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Dataset.AerialDataset import AerialDataset\n",
    "from tasks.SR3Trainer import SR3Trainer\n",
    "from models.SR3Builder import SR3Builder\n",
    "from utils.model_utils import load_model\n",
    "from utils.DDP_utils import ddp_setup"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:13:05.761416Z",
     "start_time": "2024-05-28T15:13:05.508414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Inicialization\n",
    "ddp_setup()\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 64\n",
    "dataset_dir = 'C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg'\n",
    "\n",
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = None, aux_sat_prob= 0, sat_dataset_path= \"C:\\\\Users\\\\adrianperera\\\\Desktop\\\\dataset_tfg\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler= DistributedSampler(train_dataset))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, sampler= DistributedSampler(val_dataset))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, sampler= DistributedSampler(test_dataset))\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "id": "23cc5f6f2a487382",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:56:17.593556Z",
     "start_time": "2024-05-26T23:56:17.538433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model = DDP(model_builder.build(), device_ids=[rank])#Definir q id tengo q poner\n",
    "model.to(device)"
   ],
   "id": "47acbdbe57f480a4",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T23:56:17.600245Z",
     "start_time": "2024-05-26T23:56:17.594562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\",\n",
    "    \"DDP\": True\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "c720aad7cdead033",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T00:38:57.958718Z",
     "start_time": "2024-05-26T23:56:17.601248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "2ee13c55f04b587f",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T00:38:58.006592Z",
     "start_time": "2024-05-27T00:38:57.958936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "4f6099cdb79119d0",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T00:38:58.011236Z",
     "start_time": "2024-05-27T00:38:58.006592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "76ca52491d820553",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T01:20:49.836809Z",
     "start_time": "2024-05-27T00:38:58.012241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart with l1 loss\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart l2 loss\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "16727466aaddecb9",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T01:20:49.902599Z",
     "start_time": "2024-05-27T01:20:49.837065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "aaee9864f204abca",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T01:20:49.908261Z",
     "start_time": "2024-05-27T01:20:49.902599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "251bcb3352d85919",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:32:26.663445Z",
     "start_time": "2024-05-27T01:20:49.909267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ standart\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3+\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "c0e5e79867cbfb2b",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:32:26.726244Z",
     "start_time": "2024-05-27T02:32:26.664449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)"
   ],
   "id": "361796a504f0a35d",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:32:26.732027Z",
     "start_time": "2024-05-27T02:32:26.726244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":100,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])"
   ],
   "id": "8eae72e4d3871d2a",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T03:44:18.024391Z",
     "start_time": "2024-05-27T02:32:26.733032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart with l1 loss\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ standart l1 loss\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3+\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "5e18ad7a112fecf4",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T08:16:51.365960Z",
     "start_time": "2024-05-27T08:16:51.292597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Data\n",
    "lr_size = 64\n",
    "hr_size = 256\n",
    "batch_size = 16\n",
    "dataset_dir = 'E:\\\\TFG\\\\air_dataset'\n",
    "\n",
    "transforms = Compose(\n",
    "    [RandomApply(transforms= [GaussianBlur(7)], p = 0.5),\n",
    "    RandomEqualize()]\n",
    ")\n",
    "\n",
    "dataset = AerialDataset(dataset_dir, lr_size, hr_size, data_augmentation = transforms, aux_sat_prob= 0.6, sat_dataset_path= \"E:\\\\TFG\\\\satelite_dataset\\\\64_256\")\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.6, 0.2, 0.2], generator=torch.Generator().manual_seed(420))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "d34b93b2835c22bd",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:28:37.667962Z",
     "start_time": "2024-05-27T11:28:30.208226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":200,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart with data augmentation\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart DA\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "2a90a0a9f034f694",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:07:15.173119Z",
     "start_time": "2024-05-27T11:33:13.603365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_standart()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":200,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3\",\n",
    "    \"grad_acum\": 2\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3 standart l1, DA, GA\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3 Standart l1 DA GA2\", grad_acum=hyperparams[\"grad_acum\"])\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for epoch in range(hyperparams[\"epochs\"]):  \n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader, epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    if epoch % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "25d0c3c49ec321d9",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T16:13:52.460785Z",
     "start_time": "2024-05-27T14:05:10.457813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":200,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\",\n",
    "    \"grad_acum\": 2\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart DA GA\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ Standart DA GA 2\", grad_acum= hyperparams[\"grad_acum\"])\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for epoch in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader, epoch )\n",
    "    torch.cuda.empty_cache()\n",
    "    if epoch % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "d4cfe81f2032769c",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Con data augmentation\n",
    "\n",
    "model_builder = SR3Builder()\n",
    "model_builder = model_builder.set_sr3plus()\n",
    "model_builder = model_builder.set_losstype(\"l1\")\n",
    "model = model_builder.build()\n",
    "model.to(device)\n",
    "\n",
    "hyperparams = {\n",
    "    \"lr\":0.0002,\n",
    "    \"epochs\":60,\n",
    "    \"eta_min\":1e-7,\n",
    "    \"decay_steps\": 100000,\n",
    "    \"gamma\" : 0.5,  \n",
    "    \"model\" : \"SR3+\"\n",
    "}\n",
    "hyperparams.update(model_builder.get_hyperparameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=hyperparams[\"decay_steps\"], gamma=hyperparams[\"gamma\"])\n",
    "\n",
    "project_name = \"SR model benchmarking\"\n",
    "run_name = \"SR3+ standart l1 with data augmentation\"\n",
    "wandb.login()\n",
    "wandb.init(project=project_name, config=hyperparams, name=run_name)\n",
    "\n",
    "trainer = SR3Trainer(metrics_used=(\"ssim\", \"psnr\"), model_name=\"SR3+ Standart l1 DA\")\n",
    "trainer.set_model(model)\n",
    "trainer.set_optimizer(optimizer)\n",
    "trainer.set_scheduler(scheduler)\n",
    "for step in range(hyperparams[\"epochs\"]):\n",
    "    with torch.no_grad():\n",
    "        val_loss = trainer.validate(val_dataloader)\n",
    "    \n",
    "    train_loss = trainer.train(train_dataloader)\n",
    "    torch.cuda.empty_cache()\n",
    "    if step % 10 == 0:\n",
    "        trainer.save_model(\"saved models\\\\SR3\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": val_loss})\n",
    "    \n",
    "test_metrics = trainer.test(test_dataloader)\n",
    "wandb.log(test_metrics)\n",
    "wandb.finish()   "
   ],
   "id": "c916f18d72185b7d",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": " ",
   "id": "b69cf805488278b0",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
